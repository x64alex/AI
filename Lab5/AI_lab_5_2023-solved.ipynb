{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output for networks\n",
    "data_in = torch.Tensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "data_target = torch.Tensor([[0, 0], [0, 1], [0, 1], [1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "665ae958",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2Linear = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(2, 5)),          \n",
    "            ('sigmoid1', nn.Sigmoid()),          \n",
    "            ('linear2', nn.Linear(5, 2)),          \n",
    "            ('sigmoid2', nn.Sigmoid())\n",
    "]))\n",
    "model3Linear = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(2, 10)),          \n",
    "            ('sigmoid1', nn.Sigmoid()),          \n",
    "            ('linear2', nn.Linear(10, 20)),          \n",
    "            ('sigmoid2', nn.Sigmoid()),\n",
    "            ('linear3', nn.Linear(20, 2)),          \n",
    "            ('sigmoid3', nn.Sigmoid())\n",
    "]))\n",
    "model4Linear = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(2, 2)),          \n",
    "            ('sigmoid1', nn.Sigmoid()),          \n",
    "            ('linear2', nn.Linear(2, 3)),          \n",
    "            ('sigmoid2', nn.Sigmoid()),\n",
    "            ('linear3', nn.Linear(3, 4)),          \n",
    "            ('sigmoid3', nn.Sigmoid()),\n",
    "            ('linear4', nn.Linear(4, 2)),          \n",
    "            ('sigmoid4', nn.Sigmoid())\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePerformancePrint(model, num_epochs, data_in, data_target):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(data_in)\n",
    "        loss = criterion(outputs, data_target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss every 100 epochs\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted = model(data_in)\n",
    "        predicted = torch.round(predicted)\n",
    "        accuracy = (predicted == data_target).float().sum().item() / (len(data_target) * len(data_target[0]))\n",
    "        print('Test Accuracy: {:.2f}%'.format(accuracy*100))    \n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.data)\n",
    "        \n",
    "    data_pred = model(data_in)\n",
    "    data_pred = torch.round(data_pred)\n",
    "    print(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.1469\n",
      "Epoch [200/1000], Loss: 0.1425\n",
      "Epoch [300/1000], Loss: 0.1381\n",
      "Epoch [400/1000], Loss: 0.1334\n",
      "Epoch [500/1000], Loss: 0.1281\n",
      "Epoch [600/1000], Loss: 0.1217\n",
      "Epoch [700/1000], Loss: 0.1140\n",
      "Epoch [800/1000], Loss: 0.1048\n",
      "Epoch [900/1000], Loss: 0.0944\n",
      "Epoch [1000/1000], Loss: 0.0832\n",
      "Test Accuracy: 100.00%\n",
      "linear1.weight tensor([[-2.2263, -1.8306],\n",
      "        [-1.9214, -1.9527],\n",
      "        [-0.3409, -1.0186],\n",
      "        [-2.6145, -2.6825],\n",
      "        [ 0.8475,  0.5502]])\n",
      "linear1.bias tensor([ 0.3066,  0.2412,  0.4723,  3.9314, -0.4912])\n",
      "linear2.weight tensor([[-2.0682, -1.8502, -0.5115, -5.3385,  1.3609],\n",
      "        [-1.7886, -1.7625,  0.0470,  1.9216, -0.6632]])\n",
      "linear2.bias tensor([ 2.0509, -0.1440])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "calculatePerformancePrint(model2Linear, 1000, data_in, data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.2017\n",
      "Epoch [200/10000], Loss: 0.1949\n",
      "Epoch [300/10000], Loss: 0.1861\n",
      "Epoch [400/10000], Loss: 0.1757\n",
      "Epoch [500/10000], Loss: 0.1648\n",
      "Epoch [600/10000], Loss: 0.1547\n",
      "Epoch [700/10000], Loss: 0.1464\n",
      "Epoch [800/10000], Loss: 0.1402\n",
      "Epoch [900/10000], Loss: 0.1357\n",
      "Epoch [1000/10000], Loss: 0.1324\n",
      "Epoch [1100/10000], Loss: 0.1298\n",
      "Epoch [1200/10000], Loss: 0.1275\n",
      "Epoch [1300/10000], Loss: 0.1252\n",
      "Epoch [1400/10000], Loss: 0.1227\n",
      "Epoch [1500/10000], Loss: 0.1196\n",
      "Epoch [1600/10000], Loss: 0.1157\n",
      "Epoch [1700/10000], Loss: 0.1106\n",
      "Epoch [1800/10000], Loss: 0.1038\n",
      "Epoch [1900/10000], Loss: 0.0949\n",
      "Epoch [2000/10000], Loss: 0.0833\n",
      "Epoch [2100/10000], Loss: 0.0692\n",
      "Epoch [2200/10000], Loss: 0.0540\n",
      "Epoch [2300/10000], Loss: 0.0401\n",
      "Epoch [2400/10000], Loss: 0.0291\n",
      "Epoch [2500/10000], Loss: 0.0213\n",
      "Epoch [2600/10000], Loss: 0.0160\n",
      "Epoch [2700/10000], Loss: 0.0124\n",
      "Epoch [2800/10000], Loss: 0.0098\n",
      "Epoch [2900/10000], Loss: 0.0080\n",
      "Epoch [3000/10000], Loss: 0.0067\n",
      "Epoch [3100/10000], Loss: 0.0057\n",
      "Epoch [3200/10000], Loss: 0.0049\n",
      "Epoch [3300/10000], Loss: 0.0043\n",
      "Epoch [3400/10000], Loss: 0.0038\n",
      "Epoch [3500/10000], Loss: 0.0034\n",
      "Epoch [3600/10000], Loss: 0.0031\n",
      "Epoch [3700/10000], Loss: 0.0028\n",
      "Epoch [3800/10000], Loss: 0.0025\n",
      "Epoch [3900/10000], Loss: 0.0023\n",
      "Epoch [4000/10000], Loss: 0.0022\n",
      "Epoch [4100/10000], Loss: 0.0020\n",
      "Epoch [4200/10000], Loss: 0.0019\n",
      "Epoch [4300/10000], Loss: 0.0018\n",
      "Epoch [4400/10000], Loss: 0.0016\n",
      "Epoch [4500/10000], Loss: 0.0016\n",
      "Epoch [4600/10000], Loss: 0.0015\n",
      "Epoch [4700/10000], Loss: 0.0014\n",
      "Epoch [4800/10000], Loss: 0.0013\n",
      "Epoch [4900/10000], Loss: 0.0013\n",
      "Epoch [5000/10000], Loss: 0.0012\n",
      "Epoch [5100/10000], Loss: 0.0011\n",
      "Epoch [5200/10000], Loss: 0.0011\n",
      "Epoch [5300/10000], Loss: 0.0010\n",
      "Epoch [5400/10000], Loss: 0.0010\n",
      "Epoch [5500/10000], Loss: 0.0010\n",
      "Epoch [5600/10000], Loss: 0.0009\n",
      "Epoch [5700/10000], Loss: 0.0009\n",
      "Epoch [5800/10000], Loss: 0.0009\n",
      "Epoch [5900/10000], Loss: 0.0008\n",
      "Epoch [6000/10000], Loss: 0.0008\n",
      "Epoch [6100/10000], Loss: 0.0008\n",
      "Epoch [6200/10000], Loss: 0.0008\n",
      "Epoch [6300/10000], Loss: 0.0007\n",
      "Epoch [6400/10000], Loss: 0.0007\n",
      "Epoch [6500/10000], Loss: 0.0007\n",
      "Epoch [6600/10000], Loss: 0.0007\n",
      "Epoch [6700/10000], Loss: 0.0007\n",
      "Epoch [6800/10000], Loss: 0.0006\n",
      "Epoch [6900/10000], Loss: 0.0006\n",
      "Epoch [7000/10000], Loss: 0.0006\n",
      "Epoch [7100/10000], Loss: 0.0006\n",
      "Epoch [7200/10000], Loss: 0.0006\n",
      "Epoch [7300/10000], Loss: 0.0006\n",
      "Epoch [7400/10000], Loss: 0.0005\n",
      "Epoch [7500/10000], Loss: 0.0005\n",
      "Epoch [7600/10000], Loss: 0.0005\n",
      "Epoch [7700/10000], Loss: 0.0005\n",
      "Epoch [7800/10000], Loss: 0.0005\n",
      "Epoch [7900/10000], Loss: 0.0005\n",
      "Epoch [8000/10000], Loss: 0.0005\n",
      "Epoch [8100/10000], Loss: 0.0005\n",
      "Epoch [8200/10000], Loss: 0.0005\n",
      "Epoch [8300/10000], Loss: 0.0005\n",
      "Epoch [8400/10000], Loss: 0.0004\n",
      "Epoch [8500/10000], Loss: 0.0004\n",
      "Epoch [8600/10000], Loss: 0.0004\n",
      "Epoch [8700/10000], Loss: 0.0004\n",
      "Epoch [8800/10000], Loss: 0.0004\n",
      "Epoch [8900/10000], Loss: 0.0004\n",
      "Epoch [9000/10000], Loss: 0.0004\n",
      "Epoch [9100/10000], Loss: 0.0004\n",
      "Epoch [9200/10000], Loss: 0.0004\n",
      "Epoch [9300/10000], Loss: 0.0004\n",
      "Epoch [9400/10000], Loss: 0.0004\n",
      "Epoch [9500/10000], Loss: 0.0004\n",
      "Epoch [9600/10000], Loss: 0.0004\n",
      "Epoch [9700/10000], Loss: 0.0004\n",
      "Epoch [9800/10000], Loss: 0.0003\n",
      "Epoch [9900/10000], Loss: 0.0003\n",
      "Epoch [10000/10000], Loss: 0.0003\n",
      "Test Accuracy: 100.00%\n",
      "linear1.weight tensor([[ 1.1459,  0.3107],\n",
      "        [-1.4293, -0.6428],\n",
      "        [-3.1645, -3.1472],\n",
      "        [ 2.3686,  2.3180],\n",
      "        [-1.0755, -1.8342],\n",
      "        [ 1.6408,  1.7384],\n",
      "        [ 1.7673,  1.6966],\n",
      "        [ 0.4943,  0.5214],\n",
      "        [ 1.4610,  2.2477],\n",
      "        [ 2.1075,  1.3812]])\n",
      "linear1.bias tensor([ 0.0121,  0.5400,  4.2779, -1.7695,  1.0802, -0.7626, -1.0499,  0.5206,\n",
      "        -1.1337, -1.3940])\n",
      "linear2.weight tensor([[ 9.5667e-02,  1.0949e-01,  9.8375e-01, -6.3429e-01,  5.3889e-01,\n",
      "          1.4163e-01, -3.3936e-01,  2.7700e-02, -3.5335e-01, -1.7138e-01],\n",
      "        [ 8.4085e-02, -1.1056e-01, -6.1641e-01, -7.1618e-02,  9.9295e-02,\n",
      "          1.7670e-01,  5.9373e-02, -5.8912e-02,  3.5963e-01,  2.4363e-01],\n",
      "        [-1.9501e-01, -2.7281e-01, -3.4678e-01,  7.5612e-01, -5.5715e-01,\n",
      "          5.6936e-01,  6.7233e-01,  3.0837e-02,  5.5244e-02,  5.3980e-01],\n",
      "        [ 5.7470e-01, -4.4597e-01, -1.4296e+00,  1.2662e+00, -8.3986e-01,\n",
      "          8.1126e-01,  1.0889e+00,  3.0406e-01,  9.2750e-01,  5.6204e-01],\n",
      "        [-5.2298e-02, -7.6008e-01, -3.9792e+00,  1.5004e+00, -1.4712e+00,\n",
      "          3.7002e-01,  5.6660e-01, -5.7098e-02,  8.0756e-01,  1.0924e+00],\n",
      "        [-3.6406e-02, -2.5930e-01, -6.1507e-01,  2.8929e-01, -2.6109e-01,\n",
      "          3.2523e-01,  2.2494e-01,  1.4282e-01, -1.6772e-01,  1.2411e-01],\n",
      "        [-2.9403e-01,  5.1268e-01,  8.8687e-01, -1.1017e+00,  9.0982e-01,\n",
      "         -9.0842e-01, -8.8864e-01, -2.0968e-01, -1.0218e+00, -6.7476e-01],\n",
      "        [ 7.0205e-02, -5.9674e-02, -1.2498e+00, -4.7860e-02, -4.4011e-01,\n",
      "          1.4984e-01,  1.3319e-01, -1.6217e-01,  5.7871e-02,  4.0084e-01],\n",
      "        [-2.2633e-01,  5.3536e-01,  3.5529e+00, -1.0801e+00,  1.1119e+00,\n",
      "         -2.2698e-01, -6.2765e-01,  2.2864e-01, -3.1677e-01, -9.2682e-01],\n",
      "        [-4.9728e-01,  3.0915e-01,  1.3602e+00, -1.3227e+00,  9.1039e-01,\n",
      "         -6.9528e-01, -7.6119e-01, -2.3582e-01, -1.0668e+00, -1.1354e+00],\n",
      "        [ 1.5838e-01, -1.8250e-02, -4.8163e-01,  9.3118e-03,  2.4038e-01,\n",
      "          1.6070e-01,  2.6873e-01,  1.0185e-01,  1.8126e-01, -1.1747e-01],\n",
      "        [ 2.7389e-01,  3.9704e-01,  1.9784e+00, -7.4631e-01,  7.1296e-01,\n",
      "         -1.5103e-02, -4.5530e-01,  8.4125e-02, -5.0662e-01, -1.4302e-01],\n",
      "        [ 1.5883e-01,  2.3798e-01, -4.2207e-02, -2.0090e-01,  1.1898e-01,\n",
      "         -5.8408e-02, -1.9209e-01,  1.4406e-01, -1.7635e-02,  2.6701e-03],\n",
      "        [ 2.4528e-01,  1.2257e+00,  3.7028e+00, -1.2778e+00,  1.1818e+00,\n",
      "         -4.4436e-01, -6.7282e-01,  1.3857e-01, -7.7408e-01, -9.4661e-01],\n",
      "        [-1.8843e-01,  1.8225e-01,  1.2252e+00, -9.6252e-01,  4.1552e-01,\n",
      "         -3.2205e-01, -5.3719e-01, -2.5896e-02, -8.3071e-01, -6.9385e-01],\n",
      "        [-1.7338e-01,  6.8831e-01,  1.2689e+00, -1.1855e+00,  9.4156e-01,\n",
      "         -1.2415e+00, -1.1368e+00, -1.6148e-01, -1.2063e+00, -1.2298e+00],\n",
      "        [-1.3848e-01,  6.8589e-02, -5.2380e-01, -3.7027e-02, -3.7226e-01,\n",
      "          1.9946e-01,  7.7732e-02,  1.7177e-01, -1.9502e-01,  2.8426e-01],\n",
      "        [ 3.1344e-01,  2.3244e-01, -2.6950e-01, -2.9850e-01,  3.6510e-01,\n",
      "         -9.3698e-02, -6.5383e-02,  3.4602e-02, -1.8287e-01,  2.7674e-01],\n",
      "        [ 2.0219e-01, -4.5188e-01, -1.4524e+00,  9.4781e-02, -5.3034e-01,\n",
      "          5.3218e-02,  3.8132e-01,  2.1602e-01,  2.3085e-01,  2.7761e-02],\n",
      "        [-6.8247e-01,  9.9068e-01,  2.1861e+00, -2.0875e+00,  1.0778e+00,\n",
      "         -1.3664e+00, -1.1915e+00, -1.3291e-01, -1.3130e+00, -1.0391e+00]])\n",
      "linear2.bias tensor([ 0.3549, -0.1098,  0.2461, -0.1297, -1.2119,  0.0533,  0.2192, -0.0713,\n",
      "         0.7268,  0.1751, -0.0202,  0.3845, -0.2375,  0.9108, -0.1340,  0.3490,\n",
      "         0.2447,  0.2709, -0.3980,  0.1018])\n",
      "linear3.weight tensor([[-1.3924e+00,  5.9646e-01,  6.0964e-01,  1.5193e+00,  2.3132e+00,\n",
      "          8.9623e-01, -1.1275e+00,  1.0167e+00, -2.4778e+00, -1.2052e+00,\n",
      "          3.8511e-01, -2.0833e+00, -1.2553e-01, -2.6545e+00, -1.7710e+00,\n",
      "         -1.0342e+00,  4.6851e-01, -7.0562e-02,  1.2407e+00, -1.7472e+00],\n",
      "        [-2.0939e-03, -3.5961e-01,  6.2101e-01,  1.7093e+00, -4.1490e+00,\n",
      "         -2.6490e-01, -2.0081e+00, -8.3774e-01,  2.7402e+00, -2.3179e+00,\n",
      "         -3.1980e-01,  8.7100e-01, -6.1703e-01,  3.2203e+00, -9.4887e-01,\n",
      "         -2.7511e+00, -3.7862e-01, -8.7168e-01, -1.0240e+00, -3.6752e+00]])\n",
      "linear3.bias tensor([-0.2914, -0.7476])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "calculatePerformancePrint(model3Linear, 10000, data_in, data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.2187\n",
      "Epoch [200/10000], Loss: 0.2187\n",
      "Epoch [300/10000], Loss: 0.2187\n",
      "Epoch [400/10000], Loss: 0.2187\n",
      "Epoch [500/10000], Loss: 0.2187\n",
      "Epoch [600/10000], Loss: 0.2187\n",
      "Epoch [700/10000], Loss: 0.2187\n",
      "Epoch [800/10000], Loss: 0.2187\n",
      "Epoch [900/10000], Loss: 0.2187\n",
      "Epoch [1000/10000], Loss: 0.2187\n",
      "Epoch [1100/10000], Loss: 0.2187\n",
      "Epoch [1200/10000], Loss: 0.2187\n",
      "Epoch [1300/10000], Loss: 0.2186\n",
      "Epoch [1400/10000], Loss: 0.2186\n",
      "Epoch [1500/10000], Loss: 0.2186\n",
      "Epoch [1600/10000], Loss: 0.2186\n",
      "Epoch [1700/10000], Loss: 0.2186\n",
      "Epoch [1800/10000], Loss: 0.2186\n",
      "Epoch [1900/10000], Loss: 0.2186\n",
      "Epoch [2000/10000], Loss: 0.2186\n",
      "Epoch [2100/10000], Loss: 0.2186\n",
      "Epoch [2200/10000], Loss: 0.2186\n",
      "Epoch [2300/10000], Loss: 0.2186\n",
      "Epoch [2400/10000], Loss: 0.2186\n",
      "Epoch [2500/10000], Loss: 0.2186\n",
      "Epoch [2600/10000], Loss: 0.2185\n",
      "Epoch [2700/10000], Loss: 0.2185\n",
      "Epoch [2800/10000], Loss: 0.2185\n",
      "Epoch [2900/10000], Loss: 0.2185\n",
      "Epoch [3000/10000], Loss: 0.2185\n",
      "Epoch [3100/10000], Loss: 0.2185\n",
      "Epoch [3200/10000], Loss: 0.2185\n",
      "Epoch [3300/10000], Loss: 0.2184\n",
      "Epoch [3400/10000], Loss: 0.2184\n",
      "Epoch [3500/10000], Loss: 0.2184\n",
      "Epoch [3600/10000], Loss: 0.2184\n",
      "Epoch [3700/10000], Loss: 0.2184\n",
      "Epoch [3800/10000], Loss: 0.2183\n",
      "Epoch [3900/10000], Loss: 0.2183\n",
      "Epoch [4000/10000], Loss: 0.2183\n",
      "Epoch [4100/10000], Loss: 0.2182\n",
      "Epoch [4200/10000], Loss: 0.2182\n",
      "Epoch [4300/10000], Loss: 0.2182\n",
      "Epoch [4400/10000], Loss: 0.2181\n",
      "Epoch [4500/10000], Loss: 0.2181\n",
      "Epoch [4600/10000], Loss: 0.2180\n",
      "Epoch [4700/10000], Loss: 0.2180\n",
      "Epoch [4800/10000], Loss: 0.2179\n",
      "Epoch [4900/10000], Loss: 0.2178\n",
      "Epoch [5000/10000], Loss: 0.2178\n",
      "Epoch [5100/10000], Loss: 0.2177\n",
      "Epoch [5200/10000], Loss: 0.2176\n",
      "Epoch [5300/10000], Loss: 0.2175\n",
      "Epoch [5400/10000], Loss: 0.2174\n",
      "Epoch [5500/10000], Loss: 0.2172\n",
      "Epoch [5600/10000], Loss: 0.2171\n",
      "Epoch [5700/10000], Loss: 0.2169\n",
      "Epoch [5800/10000], Loss: 0.2167\n",
      "Epoch [5900/10000], Loss: 0.2165\n",
      "Epoch [6000/10000], Loss: 0.2163\n",
      "Epoch [6100/10000], Loss: 0.2160\n",
      "Epoch [6200/10000], Loss: 0.2157\n",
      "Epoch [6300/10000], Loss: 0.2153\n",
      "Epoch [6400/10000], Loss: 0.2148\n",
      "Epoch [6500/10000], Loss: 0.2143\n",
      "Epoch [6600/10000], Loss: 0.2137\n",
      "Epoch [6700/10000], Loss: 0.2129\n",
      "Epoch [6800/10000], Loss: 0.2120\n",
      "Epoch [6900/10000], Loss: 0.2108\n",
      "Epoch [7000/10000], Loss: 0.2094\n",
      "Epoch [7100/10000], Loss: 0.2076\n",
      "Epoch [7200/10000], Loss: 0.2054\n",
      "Epoch [7300/10000], Loss: 0.2026\n",
      "Epoch [7400/10000], Loss: 0.1991\n",
      "Epoch [7500/10000], Loss: 0.1947\n",
      "Epoch [7600/10000], Loss: 0.1892\n",
      "Epoch [7700/10000], Loss: 0.1823\n",
      "Epoch [7800/10000], Loss: 0.1737\n",
      "Epoch [7900/10000], Loss: 0.1634\n",
      "Epoch [8000/10000], Loss: 0.1530\n",
      "Epoch [8100/10000], Loss: 0.1437\n",
      "Epoch [8200/10000], Loss: 0.1360\n",
      "Epoch [8300/10000], Loss: 0.1292\n",
      "Epoch [8400/10000], Loss: 0.1231\n",
      "Epoch [8500/10000], Loss: 0.1175\n",
      "Epoch [8600/10000], Loss: 0.1126\n",
      "Epoch [8700/10000], Loss: 0.1084\n",
      "Epoch [8800/10000], Loss: 0.1049\n",
      "Epoch [8900/10000], Loss: 0.1020\n",
      "Epoch [9000/10000], Loss: 0.0997\n",
      "Epoch [9100/10000], Loss: 0.0978\n",
      "Epoch [9200/10000], Loss: 0.0962\n",
      "Epoch [9300/10000], Loss: 0.0949\n",
      "Epoch [9400/10000], Loss: 0.0938\n",
      "Epoch [9500/10000], Loss: 0.0929\n",
      "Epoch [9600/10000], Loss: 0.0921\n",
      "Epoch [9700/10000], Loss: 0.0914\n",
      "Epoch [9800/10000], Loss: 0.0909\n",
      "Epoch [9900/10000], Loss: 0.0903\n",
      "Epoch [10000/10000], Loss: 0.0899\n",
      "Test Accuracy: 87.50%\n",
      "linear1.weight tensor([[1.8261, 1.9193],\n",
      "        [2.7673, 2.7108]])\n",
      "linear1.bias tensor([-3.1664, -4.4034])\n",
      "linear2.weight tensor([[ 1.8248,  2.5710],\n",
      "        [ 1.5623,  2.3727],\n",
      "        [-1.9557, -3.6699]])\n",
      "linear2.bias tensor([-2.2423, -2.0708,  2.8484])\n",
      "linear3.weight tensor([[-2.1275, -2.4007,  3.8227],\n",
      "        [-0.2071,  0.7550, -0.0861],\n",
      "        [-1.7625, -1.5341,  2.8283],\n",
      "        [-2.4103, -1.4475,  2.7492]])\n",
      "linear3.bias tensor([0.6895, 0.9746, 0.4165, 0.5180])\n",
      "linear4.weight tensor([[-3.2532,  1.6733, -2.5120, -3.1285],\n",
      "        [ 2.0404, -0.9888,  0.8435,  0.5827]])\n",
      "linear4.bias tensor([ 3.2645, -1.8785])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "calculatePerformancePrint(model4Linear, 10000, data_in, data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe18b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
